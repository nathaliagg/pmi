{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Find-data-from-each-study\" data-toc-modified-id=\"Find-data-from-each-study-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Find data from each study</a></span></li><li><span><a href=\"#Access-Literature_Sources-in-Google-Drive\" data-toc-modified-id=\"Access-Literature_Sources-in-Google-Drive-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Access Literature_Sources in Google Drive</a></span></li><li><span><a href=\"#Download-data-from-those-study-ids\" data-toc-modified-id=\"Download-data-from-those-study-ids-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Download data from those study ids</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find data from each study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I searched for `Study ID` in [Qiita](https://qiita.ucsd.edu/study/list/) and clicked on the study title, e.g. Study ID [10143](https://qiita.ucsd.edu/study/description/10143).\n",
    "\n",
    "Initially, I downloaded all the QIIME maps and BIOMs from each study, and noticed a problem. The problem was that depending on the study, there will be many analyses done (e.g., different trimming lengths), and for each analysis there will be many files including a BIOM file. It is not clear to me what is the \"final\" BIOM file, meaning the BIOM file used for the analysis in each paper. \n",
    "\n",
    "My solution was to look in the provenance of each Study ID, and select the final BIOM file from an analysis done with trimming resulting in 90 nt in length. I chose 90 nt because this length was common across the 6 studies I am working with now.\n",
    "\n",
    "**How to get the final BIOM?**  \n",
    "\n",
    "**1.** In the Study ID page, click on 16S under Data Types. The prep information will appear, and in this case, there are two preps. Click on one of the preps, and the provenance graph will appear on the right side.\n",
    "![pic1](images/picture1.png)\n",
    "\n",
    "\n",
    "**2.** In the provenance graph, click on a Trimming job (green circle). The job parameters will appear underneath the graph. Make sure length is 90. In addition, follow the line and arrow to the next gray triangle, which is the resulting trimmed sequences. Confirm the mean length in the feature summary.\n",
    "![pic2](images/picture2.png)\n",
    "![pic3](images/picture3.png)\n",
    "\n",
    "\n",
    "**3.** Then, follow the arrow to the next green circle, which should be Deblur. Ignore the black-filled triangles. Look for the deblur reference hit table. According to the Qiita [documentation](https://qiita.ucsd.edu/static/doc/html/processingdata/index.html#deblurring), the deblur reference hit table only contains 16S deblurred sequences, and the deblur final table contains all the sequences. Write the ID number in the spreadsheet of literature sources (columns ID Final Table).\n",
    "![pic4](images/picture4.png)\n",
    "\n",
    "**Repeat** this process for each prep information in each study id."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Access Literature_Sources in Google Drive\n",
    "\n",
    "1. Access the spreadsheet\n",
    "2. Get all Qiita Study ids\n",
    "3. Create directories and download biom and sample information data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wget\n",
    "import glob\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "from natsort import natsorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------\n",
    "def go_into_dir(s):\n",
    "    \"\"\"Make dir, and change dir\"\"\"\n",
    "\n",
    "    if os.path.isdir(s):\n",
    "        os.chdir(s)\n",
    "    else:\n",
    "        os.makedirs(s)\n",
    "        os.chdir(s)\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "def download_from_qiita(s):\n",
    "    \"\"\"Download i) biom + mapping files, and \n",
    "        ii) sample information from Qiita\"\"\"\n",
    "\n",
    "    biom_file = f\"biom_{s}.zip\"\n",
    "\n",
    "    sample_info = f\"sample_information_{s}.zip\"\n",
    "\n",
    "    # public data via single-end point\n",
    "    sep = \"https://qiita.ucsd.edu/public_download/?data=\"\n",
    "\n",
    "    to_download = [(biom_file, 'biom&study_id='),\n",
    "                   (sample_info, 'sample_information&study_id=')]\n",
    "\n",
    "    for t in to_download:\n",
    "        print(f'Downloading {t[0]}...')\n",
    "        cmd_to_run = f'wget -O {t[0]} \"{sep}{t[1]}{s}\"'\n",
    "        subprocess.call(cmd_to_run, shell=True)\n",
    "        print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spreadsheets = glob.glob(\"Literature_Sources-Sheet1*\")\n",
    "\n",
    "for s in spreadsheets:\n",
    "    if s in os.listdir():\n",
    "        os.remove(s)\n",
    "\n",
    "lit_source = open('source_file.txt').read().rstrip()\n",
    "filename = \"Literature_Sources-Sheet1.csv\"\n",
    "data_sources = wget.download(lit_source, out=filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download data from those study ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['714', '1609', '10141', '10143', '10321', '13450']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(filename)\n",
    "df = df[(~df['StudyID'].isna()) & (df['ID Final table'] != '-')]\n",
    "df['StudyID'] = df['StudyID'].astype(int).astype(str)\n",
    "\n",
    "study_ids = list(set(df.loc[:, 'StudyID'].dropna().to_list()))\n",
    "study_ids = natsorted([y.replace(',', \"\") for x in study_ids for y in x.split()],\n",
    "                   reverse=False)\n",
    "\n",
    "study_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for study in study_ids:\n",
    "    go_into_dir(study)\n",
    "    download_from_qiita(study)\n",
    "    os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
